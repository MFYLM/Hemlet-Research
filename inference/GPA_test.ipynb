{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from poseutils.constants import *\n",
    "from model_opr import load_model\n",
    "import sys\n",
    "import torch\n",
    "import ijson\n",
    "from math import sqrt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from draw_figure import Draw3DSkeleton\n",
    "import matplotlib.gridspec as gridspec\n",
    "from dataloader import val_loader\n",
    "from PIL import Image\n",
    "\n",
    "# from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out essential informaiton for GPA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hip', 'RHip', 'RKnee', 'RAnkle', 'LHip', 'LKnee', 'LAnkle', 'Spine', 'Neck', 'Head', 'LUpperArm', 'LElbow', 'LWrist', 'RUpperArm', 'RElbow', 'RWrist']\n",
      "[0, 24, 25, 26, 29, 30, 31, 2, 5, 6, 7, 17, 18, 19, 9, 10, 11]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16]\n",
      "Hip: 0\n",
      "RHip: 1\n",
      "RKnee: 2\n",
      "RAnkle: 3\n",
      "LHip: 4\n",
      "LKnee: 5\n",
      "LAnkle: 6\n",
      "Spine: 7\n",
      "Neck: 8\n",
      "Head: 10\n",
      "LUpperArm: 11\n",
      "LElbow: 12\n",
      "LWrist: 13\n",
      "RUpperArm: 14\n",
      "RElbow: 15\n",
      "RWrist: 16\n"
     ]
    }
   ],
   "source": [
    "print(NAMES_16)\n",
    "idx_dataset_gpa, sorted_idx_gpa = dataset_indices(\"gpa\", 16)\n",
    "# idx_dataset, sorted_idx = dataset_indices(\"h36m\", 16)\n",
    "print(idx_dataset_gpa)\n",
    "print(sorted_idx_gpa)\n",
    "\n",
    "for i in range(16):\n",
    "    print(f\"{NAMES_16[i]}: {sorted_idx_gpa[i]}\")\n",
    "\n",
    "\n",
    "JOINT_CONNECTIONS = [[1, 0], [4, 0], [7, 0],\n",
    "                     [2,1], [3,2],\n",
    "                     [5,4], [6,5],\n",
    "                     [17,7], [8,17],\n",
    "                     [14,8], [11,8], [9,8], [10,9],\n",
    "                     [15,14], [16,15],\n",
    "                     [12,11], [13,12]]\n",
    "\n",
    "\n",
    "JOINT_COLOR_INDEX = [0, 2, 1,\n",
    "                     0, 0,\n",
    "                     2, 2,\n",
    "                     1, 1,\n",
    "                     0, 2, 1, 1,\n",
    "                     0, 0,\n",
    "                     2, 2]\n",
    "\n",
    "img_mean = np.array([123.675,116.280,103.530])\n",
    "img_std = np.array([58.395,57.120,57.375])\n",
    "\n",
    "\n",
    "path_to_json = \"./GPA_dataset/xyz_gpa12_mdp_cntind_crop_cam_c2g.json\"\n",
    "path_to_imgs = \"./GPA/Gaussian_cropped_images\"\n",
    "# include modules from different directory\n",
    "sys.path.insert(1, \"/home/feiyangm/human_pose_estimation/GPA_Utils/\")\n",
    "from conversion import convert_json_to_npz_world_cam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function to read data from GPA json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json_to_npz(dataset_path, save_filename, predictions, total=None):\n",
    "    # keys: ['id', 'image_id', 'joint_cams', 'joint_imgs', 'c', 'f', 'c_c', 'c_f', 'istrains', 'istests', 'is_c2g']\n",
    "    # TODO: test this function\n",
    "\n",
    "    data_id_train = []\n",
    "    data_id_test = []\n",
    "    data_id_c2g = []\n",
    "    data_img_id_train = []\n",
    "    data_img_id_test = []\n",
    "    data_img_id_c2g = []\n",
    "    data_joint_cams_train = []\n",
    "    data_joint_cams_test = []\n",
    "    data_joint_cams_c2g = []\n",
    "    data_joint_imgs_train = []\n",
    "    data_joint_imgs_test = []\n",
    "    data_joint_imgs_c2g = []\n",
    "    data_c_train = []\n",
    "    data_c_test = []\n",
    "    data_c_c2g = []\n",
    "    data_f_train = []\n",
    "    data_f_test = []\n",
    "    data_f_c2g = []\n",
    "    data_c_c_train = []\n",
    "    data_c_c_test = []\n",
    "    data_c_c_c2g = []\n",
    "    data_c_f_train = []\n",
    "    data_c_f_test = []\n",
    "    data_c_f_c2g = []\n",
    "\n",
    "\n",
    "    with open(dataset_path, 'r') as file:\n",
    "        json_data = ijson.items(file, 'annotations.item')\n",
    "\n",
    "        for entry in tqdm(json_data, total=total):\n",
    "            id = entry['id']\n",
    "            image_id = entry['image_id']\n",
    "            # # shape becomes (34, 3)\n",
    "            joint_cams = np.transpose(np.array(entry['joint_cams'], dtype=np.float32))\n",
    "            # print(joint_cams)\n",
    "            # break\n",
    "            \n",
    "\n",
    "            \n",
    "            joint_imgs = np.array(entry['joint_imgs'], dtype=np.float32)\n",
    "            \n",
    "            c = np.array(entry['c'], dtype=np.float32)\n",
    "            f = np.array(entry['f'], dtype=np.float32)\n",
    "            c_c = np.array(entry['c_c'], dtype=np.float32)\n",
    "            c_f = np.array(entry['c_f'], dtype=np.float32)\n",
    "\n",
    "            if entry['istrains']:\n",
    "                data_id_train.append(id)\n",
    "                data_img_id_train.append(image_id)\n",
    "                data_joint_cams_train.append(joint_cams)\n",
    "                data_joint_imgs_train.append(joint_imgs)\n",
    "                data_c_train.append(c)\n",
    "                data_f_train.append(f)\n",
    "                data_c_c_train.append(c_c)\n",
    "                data_c_f_train.append(c_f)\n",
    "\n",
    "            elif entry['istests']:\n",
    "                data_id_test.append(id)\n",
    "                data_img_id_test.append(image_id)\n",
    "                data_joint_cams_test.append(joint_cams)\n",
    "                data_joint_imgs_test.append(joint_imgs)\n",
    "                data_c_test.append(c)\n",
    "                data_f_test.append(f)\n",
    "                data_c_c_test.append(c_c)\n",
    "                data_c_f_test.append(c_f)\n",
    "            \n",
    "            elif entry['is_c2g']:\n",
    "                data_id_c2g.append(id)\n",
    "                data_img_id_c2g.append(image_id)\n",
    "                data_joint_cams_c2g.append(joint_cams)\n",
    "                data_joint_imgs_c2g.append(joint_imgs)\n",
    "                data_c_c2g.append(c)\n",
    "                data_f_c2g.append(f)\n",
    "                data_c_c_c2g.append(c_c)\n",
    "                data_c_f_c2g.append(c_f)\n",
    "\n",
    "            # id 1\n",
    "            # image_id 1\n",
    "            # joint_cams 3 34\n",
    "            # joint_imgs 34 [Decimal('142.7467803955078'), Decimal('122.59777069091797')]\n",
    "            # c 2 970.0303499730985\n",
    "            # f 2 1071.506958565541\n",
    "            # c_c 2 454.6243422712787\n",
    "            # c_f 2 596.075409157109\n",
    "            # istrains True\n",
    "            # istests False\n",
    "            # is_c2g False\n",
    "\n",
    "    file.close()\n",
    "\n",
    "    print(\"c2g: \", len(data_joint_cams_c2g))\n",
    "    print(\"test: \", len(data_joint_cams_test))\n",
    "    print(\"train: \", len(data_joint_cams_train))\n",
    "\n",
    "\n",
    "    data = {\n",
    "        \"istrains\": {\n",
    "            \"id\": data_id_train,\n",
    "            \"image_id\": data_img_id_train,\n",
    "            \"joint_cams\": data_joint_cams_train,\n",
    "            \"joint_imgs\": data_joint_imgs_train,\n",
    "            \"c\": data_c_train,\n",
    "            \"f\": data_f_train,\n",
    "            \"c_c\": data_c_c_train,\n",
    "            \"c_f\": data_c_f_train,\n",
    "        },\n",
    "        \"istests\": {\n",
    "            \"id\": data_id_test,\n",
    "            \"image_id\": data_img_id_test,\n",
    "            \"joint_cams\": data_joint_cams_test,\n",
    "            \"joint_imgs\": data_joint_imgs_test,\n",
    "            \"c\": data_c_test,\n",
    "            \"f\": data_f_test,\n",
    "            \"c_c\": data_c_c_test,\n",
    "            \"c_f\": data_c_f_test,\n",
    "        },\n",
    "        \"is_c2g\": {\n",
    "            \"id\": data_id_c2g,\n",
    "            \"image_id\": data_img_id_c2g,\n",
    "            \"joint_cams\": data_joint_cams_c2g,\n",
    "            \"joint_imgs\": data_joint_imgs_c2g,\n",
    "            \"c\": data_c_c2g,\n",
    "            \"f\": data_f_c2g,\n",
    "            \"c_c\": data_c_c_c2g,\n",
    "            \"c_f\": data_c_f_c2g,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # np.savez_compressed(save_filename, data=data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPA class to allow users to pass data to dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPA(Dataset):\n",
    "    def __init__(self, path, transform=transforms.ToTensor()):\n",
    "\n",
    "        self.base_path = path\n",
    "        self.img_names = os.listdir(path)[:100]\n",
    "        self.transform = transform\n",
    "\n",
    "        # TODO: when calculating the mean, do we need to care about rgb values? will that impact the model\n",
    "        # ordering of RGB values matters to how CNN understands the images\n",
    "\n",
    "    \n",
    "\n",
    "    def normalize(self, img, flag = True):\n",
    "        if flag:\n",
    "            img = img[:,:,[2,1,0]]\n",
    "    \n",
    "        return np.divide(img - img_mean, img_std)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_name = self.img_names[index]\n",
    "        file_path = os.path.join(self.base_path, file_name)\n",
    "\n",
    "        # shape should be (256, 256, 3)\n",
    "        img = Image.open(file_path)\n",
    "        print(img.mode)\n",
    "\n",
    "        # FIXME: RGB channel is correct but it causes some predictions to be infinity...\n",
    "        img_np = np.array(img)\n",
    "        # print(img_np.shape)\n",
    "        # plt.imshow(img_np)\n",
    "        # plt.show()\n",
    "        print(type(img_np))\n",
    "\n",
    "        # preprocess the imgs\n",
    "        new_img = self.normalize(img_np)\n",
    "\n",
    "        new_img = np.transpose(new_img, (2,0,1))\n",
    "\n",
    "        img_fliped = new_img[:,:,::-1].copy()\n",
    "        img_fliped = torch.from_numpy(img_fliped).float()\n",
    "        \n",
    "        new_img = torch.from_numpy(new_img).float()\n",
    "        return new_img, img_fliped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and run with GPA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from json file and save it into a .p\n",
    "# convert_json_to_npz(path_to_json, \"./gpa_joints\")\n",
    "# joints_data = np.load(\"./gpa_joints.npz\", allow_pickle=True)\n",
    "\n",
    "\n",
    "# joints_data = joints_data['data']\n",
    "\n",
    "# # FIXME: there is no data stored inside npz file\n",
    "# print(joints_data.shape)\n",
    "\n",
    "# [\"istrain\"][\"joint_cams\"]\n",
    "\n",
    "# print(joints_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define validate function to calculate mean squared error (MSE) between predictions and actual joints coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_path ./ckpt/hemlets_h36m_lastest.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (backbone): ResNetBackbone(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_feature): TwoBranch(\n",
       "    (conv_body): Sequential(\n",
       "      (0): ConvTranspose2d(2048, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv_tail): Conv2d(256, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (conv_FBI): TwoBranch(\n",
       "    (conv_body): Sequential(\n",
       "      (0): ConvTranspose2d(2048, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv_tail): Conv2d(256, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (FBI_encoder): Sequential(\n",
       "    (0): Conv2d(60, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_tail): Sequential(\n",
       "    (0): Conv2d(1280, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(1024, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (volume_reg): CoordinateRegress()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config import config\n",
    "from network import Network\n",
    "\n",
    "# define network \n",
    "model = Network(config)\n",
    "# device = torch.device('cpu')\n",
    "device = torch.device('cuda:2') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# print(torch.cuda.current_device())\n",
    "# print(torch.cuda.memory_summary(device=device, abbreviated=False))\n",
    "torch.cuda.empty_cache()\n",
    "model = model.to(device)\n",
    "\n",
    "GPA_imgset = GPA(path_to_imgs)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(GPA_imgset, batch_size=1, shuffle=False)\n",
    "\n",
    "# load model weights\n",
    "load_model(model, \"./ckpt/hemlets_h36m_lastest.pth\", cpu=not torch.cuda.is_available())\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_pairs = np.array([[1, 4], [2, 5], [3, 6], [14, 11], [15, 12], [16, 13]], dtype=np.intc)\n",
    "\n",
    "\n",
    "def from_normjoint_to_cropspace(joint3d):\n",
    "    joint3d[:,:,:2] = (joint3d[:,:,:2] + 0.5 )*256.0\n",
    "    return joint3d\n",
    "\n",
    "\n",
    "def eval_metric(pred_joint3d_numpy, pred_joint3d_filp_numpy):\n",
    "    \n",
    "    pred_joint3d_numpy_crop = from_normjoint_to_cropspace(pred_joint3d_numpy)\n",
    "    # gt_joint3d_numpy_crop = from_normjoint_to_cropspace(gt_joint3d_numpy)\n",
    "    pred_filp_joint3d_numpy_crop = from_normjoint_to_cropspace(pred_joint3d_filp_numpy)\n",
    "\n",
    "    patch_width = 256.0\n",
    "\n",
    "    for i in range(pred_joint3d_numpy.shape[0]):\n",
    "        crop_pred_j3d = pred_joint3d_numpy_crop[i]\n",
    "        pipws_flip = pred_filp_joint3d_numpy_crop[i]\n",
    "        pipws_flip[ :, 0] = patch_width - pipws_flip[ :, 0] - 1\n",
    "        for pair in flip_pairs:\n",
    "            tmp = pipws_flip[ pair[0], :].copy()\n",
    "            pipws_flip[ pair[0], :] = pipws_flip[ pair[1], :].copy()\n",
    "            pipws_flip[ pair[1], :] = tmp.copy()\n",
    "\n",
    "        # blending flip 3D joints\n",
    "        mixJoint = (pipws_flip + crop_pred_j3d) * 0.5\n",
    "\n",
    "        mixJoint[:,2]*=128\n",
    "        return mixJoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "font = {\n",
    "    'family' : 'serif',  \n",
    "    'color'  : 'darkred',  \n",
    "    'weight' : 'normal',  \n",
    "    'size'   : 10,  \n",
    "}\n",
    "\n",
    "fig = plt.figure( figsize=(10, 10) )\n",
    "# gs1 = gridspec.GridSpec(2, 3) # 6 rows, 10 columns\n",
    "# gs1.update(left=0.08, right=0.98,top=0.95,bottom=0.08,wspace=0.05, hspace=0.1)\n",
    "axPose3d_pred=fig.add_subplot(111, projection='3d')\n",
    "plt.ion()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for img, img_fliped in dataloader:\n",
    "\n",
    "    # convert to torch.cuda.FloatTensor\n",
    "    with torch.no_grad():\n",
    "        img, img_fliped = img.to(device), img_fliped.to(device)\n",
    "\n",
    "    # # predict joint coordinates\n",
    "    pred_joint3d, pred_joint3d_fliped = model(img, val=True), model(img_fliped, val=True)\n",
    "\n",
    "    # # joints_3d = np.squeeze(pred_joint3d.detach().cpu().numpy(), axis=0)\n",
    "    # # ax = plt.figure().add_subplot(111, projection='3d')\n",
    "    pred_joint3d_ndarray, pred_joint3d_fliped_ndarray = pred_joint3d.detach().cpu().numpy(), pred_joint3d_fliped.detach().cpu().numpy()\n",
    "\n",
    "    mixJoint = eval_metric(pred_joint3d_ndarray.copy(), pred_joint3d_fliped_ndarray.copy())\n",
    "\n",
    "    Draw3DSkeleton(mixJoint, axPose3d_pred, JOINT_CONNECTIONS, 'Pred_joint3d', fontdict=font, j18_color=JOINT_COLOR_INDEX, image=None)\n",
    "\n",
    "    # TODO: convert result to camera coordinates\n",
    "\n",
    "    # ['Hip', 'RHip', 'RKnee', 'RAnkle', 'LHip', 'LKnee', 'LAnkle', 'Spine', 'Neck', 'Head', 'LUpperArm', 'LElbow', 'LWrist', 'RUpperArm', 'RElbow', 'RWrist']\n",
    "    # [0, 24, 25, 26, 29, 30, 31, 2, 5, 6, 7, 17, 18, 19, 9, 10, 11]\n",
    "    # [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16]\n",
    "\n",
    "    point = pred_joint3d_ndarray[0]\n",
    "    predictions.append(point)\n",
    "    \n",
    "    break\n",
    "\n",
    "    # ratio: 51 / 460\n",
    "    \n",
    "\n",
    "    # print(point)\n",
    "\n",
    "\n",
    "#     fig.canvas.draw()\n",
    "#     fig.canvas.flush_events()\n",
    "#     plt.pause(0.0001)\n",
    "\n",
    "#     axPose3d_pred.clear()\n",
    "#     fig.clear()\n",
    "\n",
    "# print(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check error based on first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_to_original(image):\n",
    "    image_numpy = image.cpu().numpy()\n",
    "    image_numpy = np.transpose(image_numpy, (0, 2, 3, 1))\n",
    "    image_numpy = image_numpy * img_std + img_mean\n",
    "    return image_numpy.astype(np.uint8)\n",
    "\n",
    "\n",
    "def evaluate_one_image(predicts: list, actuals: list):\n",
    "    # [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16]\n",
    "\n",
    "    mse = []\n",
    "    for i in range(len(actuals)):\n",
    "        pred_relative = predicts[i] - predicts[0]\n",
    "        actual_relative =  actuals[i] - actuals[0]\n",
    "        error = np.sqrt(np.sum(np.square(pred_relative - actual_relative)))\n",
    "        mse.append(error)\n",
    "\n",
    "    return np.mean(mse)\n",
    "\n",
    "\n",
    "def from_normjoint_to_cropspace(joint3d):\n",
    "    joint3d[:,:,:2] = (joint3d[:,:,:2] + 0.5 )*256.0\n",
    "    return joint3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2865878/2998399400.py:13: RuntimeWarning: invalid value encountered in subtract\n",
      "  pred_relative = predicts[i] - predicts[0]\n",
      "72it [00:00, 89.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "joints_errors = 0.0\n",
    "\n",
    "print(np.isnan(predictions).any())\n",
    "print(np.isfinite(predictions).any())\n",
    "print(np.isneginf(predictions).any())\n",
    "\n",
    "with open(path_to_json, 'r') as file:\n",
    "    json_data = ijson.items(file, 'annotations.item')\n",
    "\n",
    "    num = 0\n",
    "    for entry in tqdm(json_data, total=None):\n",
    "        if num > 100:\n",
    "            break\n",
    "        # id = entry['id']\n",
    "        # image_id = entry['image_id']\n",
    "        # # shape becomes (34, 3)\n",
    "        joint_cams = np.transpose(np.array(entry['joint_cams'], dtype=np.float32))[np.array(idx_dataset_gpa)]\n",
    "\n",
    "        # process z axis direction\n",
    "        joint_cams[:,2] = joint_cams[:,2] / 255.0 - 0.5\n",
    "        joint_cams[:,0:2] = joint_cams[:,0:2] / 256.0 - 0.5\n",
    "\n",
    "        # print(joint_cams)\n",
    "        # print(joint_cams.shape)\n",
    "        # print(predictions[0].shape)\n",
    "        # assert(predictions[0].shape == joint_cams.shape)\n",
    "        \n",
    "        # print(predictions.shape)\n",
    "        new_predictions = from_normjoint_to_cropspace(predictions[0][np.newaxis, :, :])\n",
    "        joint_cams = from_normjoint_to_cropspace(joint_cams[np.newaxis, :, :])\n",
    "\n",
    "    \n",
    "        # print(new_predictions[0].shape)\n",
    "        \n",
    "        # print(\"prediction: \", new_predictions)\n",
    "        # print(\"actuals normalized: \", joint_cams)\n",
    "\n",
    "\n",
    "        mse = evaluate_one_image(new_predictions[0], joint_cams[0])\n",
    "        joints_errors += mse\n",
    "        num += 1\n",
    "\n",
    "\n",
    "mse_errors_joint = joints_errors / 100\n",
    "print(mse_errors_joint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "e52da6d5556e7f74a586c11553c6407bec1da62f031655d67565f1190608da92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
